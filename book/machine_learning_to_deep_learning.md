从机器学习到深度学习：基于scikit-learn与TensorFlow的高效开发实战

# 概述
就语法分析树的解析数量是随着句子长度成Catalan 数（=(2n)!/((n+1)!n!)）增长的

## 机器学习
让计算机自己学习规则并整理规则之间的联系

机器学习系统必备的三个要素：
1. 任务：有明确的目标，比如解决某个具体的问题
2. 可度量：对任务有定量的评价方法，系统通过评估结果进行改进
3. 可成长：通过适配和训练的方式来提升能力

数据挖掘：从大量资料或资料库中提取有用信息。常常是基于某个特定的业务数据，挖掘出数据间潜在的关联信息
而机器学习则是针对一类应用场景，让机器学习到一个可以被广泛应用的知识

### 人工智能
能通过图灵测试的计算机应有4方面的能力：
1. 自然语言处理：指的是能跟人无障碍沟通的能力
2. 知识表示：知识的存储和传输
3. 自动推理：利用已有知识解决新问题
4. 机器学习：适应并预测新的情况

## 机器学习的一般流程
### 定义问题
针对任务目标，定义此次机器学习项目需要解决的问题
可以通过以下步骤来进行问题定义
1. 明确动机：问题现状（背景），新系统可以从哪些方面进行改善或优化（目标），改善后的效果和价值
2. 列出已有条件：可行性条件，准备工作，和预期的应用场景
3. 描绘解决思路：方案思路，主体流程框架

### 收集数据
#### 数据采集
数据源，信息渠道
信息的数据化：数据采样和筛选（无效数据或无关数据）
采集频率：批量、实时

#### 数据预处理
数据清理：非标数据、不满足算法处理诉求的数据
标准格式化：数据结构化、标签数字化

#### 数据转换
基于算法要求的数据格式进行数据编辑、合并和拆分

### 模型评估、比较和调试
几个概念：
+ 模型：表征已知的历史数据集。每种算法、参数（Hyperparameter）会产生不同的模型。可以直接用于学习后的预测和分类应用
+ 训练（Training）：也称Fitting，指根据数据集计算出模型的过程
+ 预测：用新的案例特征在模型上应用，以产生对新数据的判断
+ 评估（Evaluation）：检验模型效果的手段

### 应用模型
将比较选择好的模型，训练完成后，部署到正式的生产环境或迁移到移动设备上
模型迁移：在Android 和iOS 上迁移开发

## 机器学习算法的场景分类
### 有监督学习 Supervised Learning
分类（Classification）和回归（Regression）问题：本质上就是打标问题，训练的目的就是找到特征到标签的映射规律。差别是分类的标签是可数的离散类型，回归的标签是不可数的连续类型。

前提是必须有一个带标签数据的样本集（人工标注）

算法：
+ 线性回归：最小二乘法（Ordinary Least Square, OLS）、Ridge Regression、Lasso Regression、线性判别分析（Linear Discriminant Analysis）
+ 随机梯度下降（Gradient Descent）：用于寻找函数的最值。主要包括3个分支，批量梯度下降法BGD、随机梯度下降法SGD、小批量梯度下降法MBGD
+ 朴素贝叶斯（Navie Bayes）：基于概率论的分类方法，要求所有特征之间相互独立，后续研究发现当特征之间有比较平和的关联时也能打到很好的效果
+ 决策树（Decision Tree）：源自于风险管理的辅助决策系统。根据建分支的策略不同而派生的子算法：ID3、C4.5、CART等。优点是结果易理解，缺点是数据集变化时决策图变化较大
+ 支持向量机（Support Vector Machine, SVM）：被改进为可应用于非线性问题后被认为是最好的分类器
+ 高斯过程
+ 神经网络（NN）：可处理复杂的非线性问题。随着卷积网络结构的提出，发展而来的深度学习，已经成为当前非常强大的工具
+ 集成学习（Ensemble Learning）：利用多个基础分类器共同决策的方法。例如随机森林（Random Forrest）正逐步取代SVM的地位、自适应增强（AdaBoost）为代表的Boost Method

其实大多数算法都可以同时处理这两类问题

### 无监督学习
由于不需要前期的人工判断，所以它一般作为某项学习任务的前置步骤，用于规约数据。完成之后可以加入人类知识，以使成果有实用价值

+ 聚类（Clustering）问题：将已有样本数据分成若干子集
+ 数据降维（Dimensionality Reduction）：保持数据间现有距离关系不变的条件下，将高维数据转为低维数据，压缩特征数量以便后续处理
+ 其他算法族群：协方差分析（Covariance Estimation）边缘检测（Outlier Detection）等

聚类算法：
+ 距离切分方法：K-means及其派生算法、近邻算法（K-Nearest Neighbor）
+ 密度方法：通过定义每个子集的最小成员数量和成员之间距离来实现划分。最典型的算法是DBSCAN，即Density-Based Special Clustering of Applications with Noise
+ 模型方法：以概率模型（以高斯混合模型Gaussian Mixture Model为典型）和神经网络模型（Self Organizing Map, SOM）为主要代表。以模糊集的概念指出样本属于各子集的可能性。
+ 层次方法：最终将数据集划分成树形结构。这样就可以保存各个子类之间的亲缘关系。典型的是BIRCH（Balanced Iterative Reducing and Clustering using Hierarchies）

降维算法：
+ 线性降维：用于处理线性问题。常见的有主成分分析（Principe Component Analysis, PCA）、线性判别分析(Linear Discriminnant Analysis, LDA）、MDS
+ 流形学习（Manifold Learning）：处理非线性降维。比较成熟的算法包括Isomap、局部线性嵌入（Locally Linear Embedding,LLE）等

### 强化学习 Reinforced Learning
倾向于在动态环境中寻找合理的行为决策。因此行为主体是一个在某种环境下独立运行的Agent，通过训练获得在该环境中的最佳行为模式。

Agent：可以采取一系列行动以达到某种目标的控制器
环境：Agent 所能感知和控制的世界模型

Agent 和环境可以通过3种方式进行交互：
+ 状态：Agent 感知到环境情况的感知集
+ 行为：Agent 在环境中可执行的动作
+ 反馈：Agent 执行某个动作后获得的结果，可以是正向或负向的，可能是即时或延时获取的

问题场景：
+ 状态预测：用马尔科夫过程估计在任一时刻各种状态发生的可能性，其中蒙特卡洛搜索树（Monte Carlo Method）是一类重要的方法
+ 控制：控制Agent 以获得最大Reward
  + 基于策略：基于概率分布学习行为的可能性，根据可能性选择执行的动作。典型算法是Policy Gradients
  + 基于价值：直接基于Reward 学习行为结果，只能学习离散型行为，包括Q-Learning、Sarsa
  + 兼有策略和价值：如Actor-Critic

博弈原理

### 综合模型与工具
+ 隐马尔科夫模型（Hidden Markov Model, HMM）：基于概率转换的双层状态链模型。场景建模、离散和连续分布、Viterbi 算法、Baum-Welch 算法
+ 贝叶斯网络：基于条件概率节点的网络模型。网络参数估计、启发式搜索、蒙特卡洛法、MCMC、Gibbs 采样、变分贝叶斯、常用共轭分布
+ 主题模型：用三层结构分析文档的内涵主体。主要用于自然语言处理（词袋模型、TF-IDF、中文分词工具、Word2vec、非负矩阵分解等），逐步产生LSA、LDA、HDP等综合性算法，用于文档情感分析、相似文档归类等
+ 深度学习：解决机器学习问题的技术框架。TensorFlow 应用、CNN、RNN、递归神经网络、批次规范化、剪枝、优化算法、胶囊网络等

## 评估理论
### 数据集划分
将数据集划分为训练集、测试集。训练集用于模型训练，测试集用于模型评估
在划分两个集合时，需要加入随机因子，避免将同类数据划分一个数据集而导致模型无法预测另一类数据。
在明确知道数据集中的分类分层状态时，可以按某种特征进行分层采样，保证每个子数据集保持和原有数据集相同的特征比例

如果模型需要数据集调试参数，那么训练集可以再划分为训练集和验证集，验证集用于在“训练-验证”的迭代中验证参数的调校效果
从集合规模而言，训练集、验证集、测试集，应该逐级更大

#### 交叉验证
在“训练-验证”的迭代中，交叉验证是将数据集划分为若干子集，然后每次迭代，将若干子集进行组合，互作训练和验证
子集的数量n 可以自行定义，就是所谓的n-fold 交叉验证，在数据量足够的情况下，n 一般取10。若模型训练时间过长则只能降低该值

### 评估指标
二值混淆矩阵 Positive/Negative Confusion Matrix 是独立考察模型对某个标签分类能力的工具
+ TP: 阳性真判定，即确认为指定标签是正确的
+ TN: 阴性真判定，即未被认定为指定标签是正确的
+ FP: 阳性假判定，即认定为指定标签是错误的（误伤）
+ FN: 阴性假判定，即未被认定为指定标签是错误的（漏检）
准确率Accuracy=(TP+TN)/(TP+TN+FP+FN)
精准率Preision=TP/(TP+FP)，即所有阳性判定中正确的比率
召回率Recall=TP/(TP+FN)，即所有问题数据中被正确标记的比率
调和均值Harmonic Mean=2TP/(2TP+FP+FN)

### 连续值指标
可以通过统计被测样本的真实值与预测值的 平均绝对差 或 平均方差 来衡量